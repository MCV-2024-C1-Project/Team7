{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548c0602",
   "metadata": {},
   "source": [
    "# Unknown painting detection threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dce04",
   "metadata": {},
   "source": [
    "In this notebook the top2/top1 number of paintings ratio is optimized using different keypoint detection systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a5bdf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tqdm as tqdm\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.utils.images import load_images_from_directory\n",
    "from src.utils.denoising import create_denoised_dataset\n",
    "from src.utils.segmentation import generate_masks\n",
    "from src.utils.keypoint_descriptors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64fe75",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowe_ratio_test (knn_matches, ratio_threshold):\n",
    "    \"\"\"\n",
    "    Applies Lowe's ratio test to filter out poor matches from k-nearest neighbors (k-NN) match results.\n",
    "\n",
    "    Args:\n",
    "        knn_matches (list of tuples): A list of tuples where each tuple contains two matches (m, n).\n",
    "            - `m` and `n` are typically objects with a `distance` attribute, representing the \n",
    "              distance between matched features.\n",
    "        ratio_threshold (float): The threshold ratio to determine if a match is good. A smaller \n",
    "            ratio is more strict and filters out more matches.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of good matches that pass Lowe's ratio test. Each match in the list is from \n",
    "        the first element of the tuple `m` in `knn_matches` that satisfies the ratio test.\n",
    "    \"\"\"\n",
    "    good_matches = []\n",
    "    for match_pair in knn_matches:\n",
    "        if len(match_pair) >= 2:\n",
    "            m, n = match_pair[0], match_pair[1]\n",
    "            if m.distance < ratio_threshold * n.distance:\n",
    "                good_matches.append(m)\n",
    "    \n",
    "    return good_matches\n",
    "\n",
    "\n",
    "def function_time_count(function, params):\n",
    "\n",
    "    \"\"\"\n",
    "    Measures the execution time of a given function and returns both the \n",
    "    time taken and the function's result.\n",
    "\n",
    "    Args:\n",
    "        function (callable): The function to be executed.\n",
    "        params (list): A tuple of parameters to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - total_time (float): The time taken to execute the function, in seconds.\n",
    "        - results: The output of the executed function.\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    results = function(*params)\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "\n",
    "    return total_time, results\n",
    "\n",
    "\n",
    "def get_key_des_multi_image(images_list, method):\n",
    "    \"\"\"\n",
    "    Identifies keypoints and calculates descriptors for each image in\n",
    "    a list of loaded images using the specified method.\n",
    "    \n",
    "    Args:\n",
    "    - images_list (list of ndarray): list of loaded images\n",
    "    - method (str): method to use to extract the keypoints and descriptors\n",
    "    \n",
    "    Returns:\n",
    "    - key_des_list (list of dictionaries): list of dictionaries, each\n",
    "                    dictionary containing the keypoints and descriptors\n",
    "                    for each image.\n",
    "    \"\"\"\n",
    "    \n",
    "    if method==\"SIFT\":\n",
    "        key_des_list = get_SIFT_key_des_multi_image(images_list)\n",
    "    \n",
    "    elif method==\"ORB\":\n",
    "        key_des_list = get_ORB_key_des_multi_image(images_list)\n",
    "        \n",
    "    elif method==\"AKAZE\":\n",
    "        key_des_list = get_AKAZE_key_des_multi_image(images_list)\n",
    "        \n",
    "    elif method==\"Harris-SIFT\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_key, get_SIFT_descriptors)\n",
    "    \n",
    "    elif method==\"Harris-ORB\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_key, get_ORB_descriptors)\n",
    "\n",
    "    elif method==\"Harris-AKAZE\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_key, get_AKAZE_descriptors)\n",
    "    \n",
    "    elif method==\"HarrisLaplacian-SIFT\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_Laplacian_keypoints, get_SIFT_descriptors)\n",
    "    \n",
    "    elif method==\"HarrisLaplacian-ORB\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_Laplacian_keypoints, get_ORB_descriptors)\n",
    "    \n",
    "    elif method==\"HarrisLaplacian-AKAZE\":\n",
    "        key_des_list = get_key_des_wildcard_multi_image(images_list, get_Harris_Laplacian_keypoints, get_AKAZE_descriptors)\n",
    "    \n",
    "    return key_des_list\n",
    "\n",
    "def get_num_matching_descriptors(descriptors_image_1, descriptors_image_2, method, descr_method, params=[]):\n",
    "    \"\"\"\n",
    "    Matches descriptors between two images using either Brute-Force or FLANN-based matching.\n",
    "\n",
    "    Parameters:\n",
    "        descriptors_image_1: ndarray\n",
    "            Descriptors from the first image.\n",
    "        descriptors_image_2: ndarray\n",
    "            Descriptors from the second image.\n",
    "        method: str\n",
    "            Matching method to use. Options:\n",
    "            - \"BruteForce\": Uses Brute-Force matcher.\n",
    "            - \"FLANN\": Uses FLANN-based matcher.\n",
    "        descr_method: str\n",
    "            Descriptor method used for extracting features. Options:\n",
    "            - \"SIFT\": Uses floating-point descriptors.\n",
    "            - \"ORB\", \"AKAZE\": Use binary descriptors.\n",
    "        params: list, optional\n",
    "            Additional parameters depending on the method:\n",
    "            - For \"BruteForce\":\n",
    "                params[0]: int\n",
    "                    Norm type (default: cv2.NORM_L2 for SIFT, cv2.NORM_HAMMING for ORB/AKAZE).\n",
    "                params[1]: bool\n",
    "                    Whether to use crossCheck (default = False).\n",
    "            - For \"FLANN\":\n",
    "                params[0]: dict\n",
    "                    Index parameters.\n",
    "                params[1]: dict\n",
    "                    Search parameters.\n",
    "                params[2]: int\n",
    "                    Number of nearest neighbors (k) (default: 5).\n",
    "                params[3]: float\n",
    "                    Lowe's ratio for filtering matches (default: 0.7).\n",
    "\n",
    "    Returns:\n",
    "    - tuple:\n",
    "        - matches: list\n",
    "            List of matched descriptors.\n",
    "        - num_matches: int\n",
    "            The number of matches found.\n",
    "\n",
    "    Notes:\n",
    "    - BruteForce:\n",
    "        - Uses Euclidean distance for SIFT.\n",
    "        - Uses Hamming distance for ORB and AKAZE.\n",
    "    - FLANN:\n",
    "        - Uses KDTree for SIFT.\n",
    "        - Uses LSH for ORB and AKAZE.\n",
    "        - Applies Lowe's ratio test for FLANN-based matches.\n",
    "    \"\"\"\n",
    "    if method == \"BruteForce\":\n",
    "        if descr_method in [\"SIFT\", \"Harris-SIFT\", \"HarrisLaplacian-SIFT\"]:\n",
    "            if params:\n",
    "                norm = params[0]\n",
    "                crossCheck = params[1]\n",
    "            else:\n",
    "                norm = cv2.NORM_L2\n",
    "                crossCheck = False\n",
    "\n",
    "        elif descr_method in [\"ORB\",\"AKAZE\", \"Harris-ORB\", \"Harris-AKAZE\", \"HarrisLaplacian-ORB\", \"HarrisLaplacian-AKAZE\"]:\n",
    "            if params:\n",
    "                norm = params[0]\n",
    "                crossCheck = params[1]\n",
    "            else:\n",
    "                norm = cv2.NORM_HAMMING\n",
    "                crossCheck = False\n",
    "        else:\n",
    "            norm = cv2.NORM_HAMMING\n",
    "            crossCheck = True\n",
    "\n",
    "        matcher = cv2.BFMatcher(norm, crossCheck)\n",
    "        matches = matcher.match(descriptors_image_1, descriptors_image_2)\n",
    "        num_matches = len(matches)\n",
    "\n",
    "    elif method == \"FLANN\":\n",
    "        if descr_method == \"SIFT\":\n",
    "            if params:\n",
    "                index_params = params[0]\n",
    "                search_params = params[1]\n",
    "                k = params[2]\n",
    "                ratio = params[3]\n",
    "            else:\n",
    "                index_params = dict(algorithm=1, trees=5)\n",
    "                search_params = dict(checks=50)\n",
    "                k = 2\n",
    "                ratio = 0.7\n",
    "\n",
    "        elif descr_method in [\"ORB\",\"AKAZE\"]:\n",
    "            if params:\n",
    "                index_params = params[0]\n",
    "                search_params = params[1]\n",
    "                k = params[2]\n",
    "                ratio = params[3]\n",
    "            else:\n",
    "                index_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)\n",
    "                search_params = dict(checks=50)\n",
    "                k = 2\n",
    "                ratio = 0.7\n",
    "        \n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        knn_matches = matcher.knnMatch(descriptors_image_1, descriptors_image_2, k)\n",
    "        matches = lowe_ratio_test(knn_matches, ratio)\n",
    "        num_matches = len(matches)\n",
    "\n",
    "    return matches, num_matches\n",
    "\n",
    "\n",
    "def check_for_unknown_painting(num_matching_descriptors_list, unknown_painting_threshold):\n",
    "    \"\"\"\n",
    "    Determines whether an unknown painting is present by analyzing the ratio of matching descriptors.\n",
    "\n",
    "    Args:\n",
    "        num_matching_descriptors_list (list of int): A list containing the number of matching \n",
    "            descriptors for each known painting.\n",
    "        unknown_painting_threshold (float): The threshold ratio used to determine if the painting \n",
    "            is unknown. If the ratio of the second highest to the highest number of matches exceeds \n",
    "            this threshold, the painting is considered unknown.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the painting is determined to be unknown, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    matching_list_aux = sorted(num_matching_descriptors_list, reverse=True)\n",
    "    max_matches = matching_list_aux[0]\n",
    "    second_max_matches = matching_list_aux[1]\n",
    "\n",
    "    ratio = second_max_matches / (max_matches+0.000001)\n",
    "\n",
    "    return ratio\n",
    "\n",
    "\n",
    "def get_num_matches(query_dir, bbdd_dir, method, matching_method, matching_params=[],\n",
    "                    cache_segmented=False, cache_denoised=False):\n",
    "    \"\"\"\n",
    "    Processes query images to identify paintings by matching their features against a database (BBDD),\n",
    "    using specified image processing and matching methods. Only returns the number of matching descriptors\n",
    "    per query per bbdd in a list of lists.\n",
    "\n",
    "    This function involves several steps: denoising, segmentation, feature extraction, and descriptor \n",
    "    matching. The process is optimized with optional caching for segmentation and denoising.\n",
    "\n",
    "    Args:\n",
    "        query_dir (str): Path to the directory containing query images.\n",
    "        bbdd_dir (str): Path to the directory containing database (BBDD) images.\n",
    "        method (str): Method used for extracting keypoints and descriptors (e.g., SIFT, ORB).\n",
    "        matching_method (str): Method used for matching descriptors (e.g., brute-force, FLANN).\n",
    "        matching_params (list, optional): Additional parameters for the matching method.\n",
    "        unknown_painting_threshold (float, optional): Threshold for determining if a painting is unknown.\n",
    "            Default is 2.\n",
    "        cache_segmented (bool, optional): If True, uses cached segmented images. Default is False.\n",
    "        cache_denoised (bool, optional): If True, uses cached denoised images. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists with the number of matching descriptors between each query and\n",
    "              database image.\n",
    "    \"\"\"\n",
    "        \n",
    "    if cache_segmented:\n",
    "        print(\"Using cached segmented images.\")\n",
    "        \n",
    "    if cache_denoised:\n",
    "        print(\"Using cached denoised images.\")\n",
    "    \n",
    "    # REMOVE NOISE FROM QUERY IMAGES FOR SEGMENTATION\n",
    "    # ======================================================================================\n",
    "\n",
    "    # Create a new directory for denoised images\n",
    "    denoised_for_segmentation_queries_dir = 'data/denoised_for_segmentation_queries_dir'\n",
    "\n",
    "    if not cache_segmented:\n",
    "        # Remove previous denoised images\n",
    "        if os.path.exists(denoised_for_segmentation_queries_dir):\n",
    "            shutil.rmtree(denoised_for_segmentation_queries_dir)\n",
    "\n",
    "        # Execute denoising method 1\n",
    "        create_denoised_dataset(\n",
    "            noisy_dataset_path = query_dir,\n",
    "            denoised_dataset_path = denoised_for_segmentation_queries_dir,\n",
    "            method='gaussian',\n",
    "            lowpass_params={'ksize': 3},\n",
    "            highpass=False\n",
    "        )\n",
    "\n",
    "        # Read denoised images\n",
    "        rgb_queries_denoised = []\n",
    "        for filename in os.listdir(denoised_for_segmentation_queries_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(denoised_for_segmentation_queries_dir, filename)\n",
    "                img_rgb = cv2.imread(img_path)\n",
    "                if img_rgb is not None:\n",
    "                    rgb_queries_denoised.append(img_rgb)\n",
    "                else:\n",
    "                    print(f\"Warning: Failed to read {img_path}\")\n",
    "\n",
    "\n",
    "    # DETECT PAINTINGS IN QUERIES (SEGMENTATION)\n",
    "    # ======================================================================================\n",
    "\n",
    "    masks_queries_dir = \"data/masks_queries_dir\"\n",
    "    cropped_queries_dir = \"data/cropped_queries_dir\"\n",
    "\n",
    "    if not cache_segmented:\n",
    "        # Remove previous masks and cropped images\n",
    "        if os.path.exists(masks_queries_dir):\n",
    "            shutil.rmtree(masks_queries_dir)\n",
    "        if os.path.exists(cropped_queries_dir):\n",
    "            shutil.rmtree(cropped_queries_dir)\n",
    "\n",
    "        # Create new directories for masks and cropped images\n",
    "        os.makedirs(masks_queries_dir, exist_ok=True)\n",
    "        os.makedirs(cropped_queries_dir, exist_ok=True)\n",
    "\n",
    "        masks = generate_masks(rgb_queries_denoised)\n",
    "\n",
    "        # Read query images\n",
    "        rgb_queries = []\n",
    "        for filename in os.listdir(query_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(query_dir, filename)\n",
    "                img_rgb = cv2.imread(img_path)\n",
    "                if img_rgb is not None:\n",
    "                    rgb_queries.append(img_rgb)\n",
    "                else:\n",
    "                    print(f\"Warning: Failed to read {img_path}\")\n",
    "\n",
    "        paintings_per_image = []\n",
    "        image_counter = 0\n",
    "\n",
    "        for i, mask in enumerate(tqdm(masks, desc=\"Generating segmentation masks and cropping images\")):\n",
    "            # Save the mask\n",
    "            mask_filename = f\"{i:05d}.png\"\n",
    "            masks_save_path = os.path.join(masks_queries_dir, mask_filename)\n",
    "            cv2.imwrite(masks_save_path, mask)\n",
    "\n",
    "            # Detect connected components in the mask\n",
    "            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "            # Count paintings (objects of interest) in the current image\n",
    "            painting_count = 0\n",
    "\n",
    "            # Collect all valid components (ignoring background label 0)\n",
    "            components = []\n",
    "\n",
    "            for j in range(1, num_labels):\n",
    "                x, y, w, h, area = stats[j]\n",
    "\n",
    "                components.append((x, y, w, h, area))  # Store component details\n",
    "\n",
    "            # Sort components from leftmost to rightmost (higher x to lower x)\n",
    "            components_sorted = sorted(components, key=lambda c: c[0])\n",
    "\n",
    "            # Iterate over sorted components and save them\n",
    "            for (x, y, w, h, area) in components_sorted:\n",
    "                # Extract and save the cropped region\n",
    "                cropped_result = rgb_queries[i][y:y+h, x:x+w]\n",
    "                cropped_filename = f\"{image_counter:05d}.jpg\"\n",
    "                cropped_save_path = os.path.join(cropped_queries_dir, cropped_filename)\n",
    "                cv2.imwrite(cropped_save_path, cropped_result)\n",
    "\n",
    "                # Increment the counter for unique naming\n",
    "                image_counter += 1\n",
    "                painting_count += 1\n",
    "\n",
    "            # Add the number of paintings detected for this image to the list\n",
    "            paintings_per_image.append(painting_count)\n",
    "\n",
    "        # Save the list of frame counts per image in a single .pkl file\n",
    "        with open(\"data/paintings_per_image.pkl\", \"wb\") as f:\n",
    "            pickle.dump(paintings_per_image, f)\n",
    "\n",
    "\n",
    "    # REMOVE NOISE FROM QUERY IMAGES\n",
    "    # =======================================================================================\n",
    "\n",
    "    # Load list containing paintings per image\n",
    "    with open('data/paintings_per_image.pkl', 'rb') as file:\n",
    "        paintings_per_image = pickle.load(file)\n",
    "\n",
    "    denoised_paintings_folder = 'data/denoised_paintings'\n",
    "\n",
    "    if not cache_denoised:\n",
    "        # Remove previous paintings\n",
    "        if os.path.exists(denoised_paintings_folder):\n",
    "            shutil.rmtree(denoised_paintings_folder)\n",
    "\n",
    "        # Create new temporary directory for denoised images\n",
    "        os.makedirs(denoised_paintings_folder, exist_ok=True)\n",
    "\n",
    "        # Using denoising method 5\n",
    "        create_denoised_dataset(\n",
    "            noisy_dataset_path = cropped_queries_dir,\n",
    "            denoised_dataset_path = denoised_paintings_folder,\n",
    "            method='wavelet',\n",
    "            wavelet_params={'wavelet':'db1', 'mode':'soft', 'rescale_sigma':True},\n",
    "            highpass=False\n",
    "        )\n",
    "\n",
    "\n",
    "    # EXTRACT LOCAL FEATURES (KEYPOINT DESCRIPTORS) FROM\n",
    "    # DENOISED QUERIES AND BBDD\n",
    "    # =======================================================================================\n",
    "\n",
    "    # Load denoised query paintings and bbdd images\n",
    "    query_images = load_images_from_directory(denoised_paintings_folder)\n",
    "    bbdd_images = load_images_from_directory(bbdd_dir)\n",
    "\n",
    "    # Extract keypoints and descriptors\n",
    "    query_key_des_list = get_key_des_multi_image(query_images, method)\n",
    "    bbdd_key_des_list = get_key_des_multi_image(bbdd_images, method)\n",
    "    \n",
    "    # Results matrix\n",
    "    full_matching_descriptors = []\n",
    "    \n",
    "    # For each query\n",
    "    for query_image in tqdm(query_key_des_list, desc=\"Matching descriptors\"):\n",
    "        \n",
    "        # Get matching descriptors from each bbdd image\n",
    "        num_matching_descriptors_list = []\n",
    "        for bbdd_image in bbdd_key_des_list:\n",
    "            \n",
    "            # There must be at least one descriptor in the bbdd image\n",
    "            if str(bbdd_image['descriptors'])!=\"None\":\n",
    "                _, num_matching_descriptors = get_num_matching_descriptors(query_image['descriptors'],\n",
    "                                                                           bbdd_image['descriptors'],\n",
    "                                                                           method=matching_method,\n",
    "                                                                           descr_method=method,\n",
    "                                                                           params=matching_params)\n",
    "            else:\n",
    "                num_matching_descriptors = 0\n",
    "                \n",
    "            num_matching_descriptors_list.append(num_matching_descriptors)\n",
    "        \n",
    "        full_matching_descriptors.append(num_matching_descriptors_list)\n",
    "    \n",
    "    return full_matching_descriptors\n",
    "\n",
    "def generate_submission(results, paintings_per_image):\n",
    "    \"\"\"\n",
    "    Gets the top 1 bbdd image for each query, taking into account\n",
    "    whether there were one or two paintings in the image.\n",
    "    \n",
    "    Args:\n",
    "    - results: list of lists with the ordered top results for each query\n",
    "    - paintings_per_image: list with number of paintings in every query image\n",
    "    \n",
    "    Returns:\n",
    "    - submission: a list of lists in the sumbission format\n",
    "    \"\"\"\n",
    "    \n",
    "    submission = []\n",
    "    i = 0\n",
    "    for num_paintings in paintings_per_image:\n",
    "        if num_paintings == 1:\n",
    "            submission.append([results[i][0]])\n",
    "            i += 1\n",
    "        elif num_paintings == 2:\n",
    "            submission.append([results[i][0], results[i+1][0]])\n",
    "            i += 2\n",
    "            \n",
    "    return submission\n",
    "\n",
    "def order_results_by_num_paintings(results, paintings_per_image):\n",
    "    \n",
    "    ordered_results = []\n",
    "    i = 0\n",
    "    for num_paintings in paintings_per_image:\n",
    "        if num_paintings == 1:\n",
    "            ordered_results.append([results[i]])\n",
    "            i += 1\n",
    "        elif num_paintings == 2:\n",
    "            ordered_results.append([results[i], results[i+1]])\n",
    "            i += 2\n",
    "            \n",
    "    return ordered_results\n",
    "    \n",
    "def get_unknowns_f1(submission, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates the f1 score considering only the predictions regarding\n",
    "    the unknown paintings.\n",
    "    \n",
    "    Args:\n",
    "    - submission: results in the submission format.\n",
    "    - ground_truth: groundtruth in the W4 format.\n",
    "    \n",
    "    Returns:\n",
    "    - f1: f1 score regarding the unknown paintings predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    submission_binary = [1 if sublist[0] == -1 else 0 for sublist in submission]\n",
    "    groundtruth_binary = [1 if sublist[0] == -1 else 0 for sublist in ground_truth]\n",
    "\n",
    "    f1 = f1_score(groundtruth_binary, submission_binary)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def get_top_two_max(full_matching_descriptors):\n",
    "    top_two_list = []\n",
    "    for matching_list in full_matching_descriptors:\n",
    "        top_two = sorted(matching_list, reverse=True)[0:2]\n",
    "        top_two_list.append(top_two)\n",
    "    return top_two_list\n",
    "\n",
    "def remove_multiple_painting_entries(list1, list2):\n",
    "    \n",
    "    # Check if both lists are of the same size\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same size.\")\n",
    "    \n",
    "    # Iterate over list2 with index to find where elements are sublists of length 2\n",
    "    indices_to_remove = [i for i, item in enumerate(list2) if isinstance(item, list) and len(item) == 2]\n",
    "    \n",
    "    # Remove elements in reverse order to avoid index shifting\n",
    "    for index in sorted(indices_to_remove, reverse=True):\n",
    "        del list1[index]\n",
    "        del list2[index]\n",
    "    \n",
    "    return list1, list2\n",
    "\n",
    "def check_for_unknown_painting_modified(num_matching_descriptors_list, unknown_painting_threshold):\n",
    "    \n",
    "    max_matches = num_matching_descriptors_list[0]\n",
    "    second_max_matches = num_matching_descriptors_list[1]\n",
    "    \n",
    "    ratio = second_max_matches / (max_matches + 0.0000001)\n",
    "\n",
    "    return int(ratio > unknown_painting_threshold)\n",
    "\n",
    "def get_unknown_vector(predictions_list):\n",
    "    return [1 if sublist[0] == -1 else 0 for sublist in predictions_list]\n",
    "\n",
    "def get_unknown_paintings(filtered_matchings, unknown_painting_threshold):\n",
    "    unknown_predictions = []\n",
    "    for query in filtered_matchings:\n",
    "        uknown = check_for_unknown_painting_modified(query[0], unknown_painting_threshold)\n",
    "        unknown_predictions.append(uknown)\n",
    "    return unknown_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9fcbd",
   "metadata": {},
   "source": [
    "### Main function that performs the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f30418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_unknown_painting_threshold_optimization(query_dir, bbdd_dir,\n",
    "                                                    method,\n",
    "                                                    matching_method,\n",
    "                                                    matching_params=[],\n",
    "                                                    cache_segmented=False,\n",
    "                                                    cache_denoised=False):\n",
    "    \n",
    "    full_matching_descriptors = get_num_matches(query_dir, bbdd_dir,\n",
    "                                                method,\n",
    "                                                matching_method,\n",
    "                                                matching_params,\n",
    "                                                cache_segmented,\n",
    "                                                cache_denoised)\n",
    "    \n",
    "    with open(\"data/paintings_per_image.pkl\", \"rb\") as f:\n",
    "        paintings_per_image = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(query_dir, 'gt_corresps.pkl'), 'rb') as f:\n",
    "        ground_truth = pickle.load(f)\n",
    "        \n",
    "    print(\"Executing unknown painting threshold optimization for parameters\", method, matching_method, matching_params)\n",
    "\n",
    "    # Preprocess results\n",
    "    # ===================================================================================================\n",
    "    # Get the top two number of matchings per query\n",
    "    top_two_matching_list = get_top_two_max(full_matching_descriptors)\n",
    "\n",
    "    # Pair paintings corresponding to the same image in a submission-like manner\n",
    "    ordered_matchings = order_results_by_num_paintings(top_two_matching_list, paintings_per_image)\n",
    "\n",
    "    # Only consider images with 1 painting, so cropping issues are not taken\n",
    "    # into account by the threshold optimization process.\n",
    "    filtered_matchings, filtered_gt = remove_multiple_painting_entries(ordered_matchings, ground_truth)\n",
    "\n",
    "    # Convert filtered groundtruth to 0s and 1s vectors (1 if unknown, 0 otherwise), so we can\n",
    "    # later caluclate the f1 more easily\n",
    "    gt_vector = get_unknown_vector(filtered_gt)\n",
    "    \n",
    "    # Optimize threshold\n",
    "    # ===================================================================================================\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Loop over the threshold grid, from 0.01 to 0.99 with a step of 0.0001\n",
    "    for threshold in np.arange(0.01, 1.00, 0.0001):\n",
    "        # Get predictions for the current threshold\n",
    "        unknown_preds = get_unknown_paintings(filtered_matchings, unknown_painting_threshold=threshold)\n",
    "\n",
    "        # Calculate F1 score for the current threshold\n",
    "        f1 = f1_score(gt_vector, unknown_preds)\n",
    "\n",
    "        # Append the threshold and corresponding F1 score to the results list\n",
    "        results.append({'threshold': threshold, 'f1_score': f1})\n",
    "\n",
    "    # Convert results to a DataFrame for easier retrieval and analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Find the threshold with the best (highest) F1 score\n",
    "    best_result = results_df.loc[results_df['f1_score'].idxmax()]\n",
    "\n",
    "    # Print the best threshold and corresponding F1 score\n",
    "    print(\"Best Threshold:\", best_result['threshold'])\n",
    "    print(\"Best F1 Score:\", best_result['f1_score'])\n",
    "    \n",
    "    return top_two_matching_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f2c2f",
   "metadata": {},
   "source": [
    "### Parameter optimization for different keypoint descriptor methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfbd169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising images: 100%|████████████████████████████████████████████████████████████████| 94/94 [00:02<00:00, 40.80it/s]\n",
      "Generating segmentation masks and cropping images: 100%|███████████████████████████████| 30/30 [00:01<00:00, 18.35it/s]\n",
      "Denoising images: 100%|████████████████████████████████████████████████████████████████| 37/37 [00:30<00:00,  1.20it/s]\n",
      "Extracting keypoints and descriptors: 100%|████████████████████████████████████████████| 37/37 [00:02<00:00, 18.21it/s]\n",
      "Extracting keypoints and descriptors: 100%|██████████████████████████████████████████| 287/287 [00:07<00:00, 36.28it/s]\n",
      "Matching descriptors: 100%|████████████████████████████████████████████████████████████| 37/37 [00:26<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing unknown painting threshold optimization for parameters ORB FLANN []\n",
      "Best Threshold: 0.506199999999997\n",
      "Best F1 Score: 0.8695652173913044\n"
     ]
    }
   ],
   "source": [
    "query_dir = \"./data/qsd1_w4/\"\n",
    "bbdd_dir = \"./data/BBDD/\"\n",
    "\n",
    "execute_unknown_painting_threshold_optimization(query_dir, bbdd_dir,\n",
    "                                                method=\"ORB\",\n",
    "                                                matching_method=\"FLANN\",\n",
    "                                                matching_params=[],\n",
    "                                                cache_segmented=False,\n",
    "                                                cache_denoised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a5b3b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising images: 100%|████████████████████████████████████████████████████████████████| 94/94 [00:01<00:00, 48.11it/s]\n",
      "Generating segmentation masks and cropping images: 100%|███████████████████████████████| 30/30 [00:01<00:00, 21.14it/s]\n",
      "Denoising images: 100%|████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.23it/s]\n",
      "Extracting keypoints and descriptors: 100%|████████████████████████████████████████████| 37/37 [00:00<00:00, 37.49it/s]\n",
      "Extracting keypoints and descriptors: 100%|██████████████████████████████████████████| 287/287 [00:07<00:00, 39.32it/s]\n",
      "Matching descriptors: 100%|████████████████████████████████████████████████████████████| 37/37 [00:28<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing unknown painting threshold optimization for parameters ORB BruteForce [6, True]\n",
      "Best Threshold: 0.9280999999999945\n",
      "Best F1 Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "query_dir = \"./data/qsd1_w4/\"\n",
    "bbdd_dir = \"./data/BBDD/\"\n",
    "\n",
    "execute_unknown_painting_threshold_optimization(query_dir, bbdd_dir,\n",
    "                                                method=\"ORB\",\n",
    "                                                matching_method=\"BruteForce\",\n",
    "                                                matching_params=[cv2.NORM_HAMMING, True],\n",
    "                                                cache_segmented=False,\n",
    "                                                cache_denoised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7659cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached segmented images.\n",
      "Using cached denoised images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keypoints and descriptors: 100%|████████████████████████████████████████████| 37/37 [00:08<00:00,  4.13it/s]\n",
      "Extracting keypoints and descriptors: 100%|██████████████████████████████████████████| 287/287 [01:36<00:00,  2.97it/s]\n",
      "Matching descriptors: 100%|█████████████████████████████████████████████████████████| 37/37 [1:12:02<00:00, 116.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing unknown painting threshold optimization for parameters AKAZE BruteForce [6, True]\n",
      "Best Threshold: 0.8685999999999948\n",
      "Best F1 Score: 0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "query_dir = \"./data/qsd1_w4/\"\n",
    "bbdd_dir = \"./data/BBDD/\"\n",
    "\n",
    "execute_unknown_painting_threshold_optimization(query_dir, bbdd_dir,\n",
    "                                                method=\"AKAZE\",\n",
    "                                                matching_method=\"BruteForce\",\n",
    "                                                matching_params=[cv2.NORM_HAMMING, True],\n",
    "                                                cache_segmented=True,\n",
    "                                                cache_denoised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32f5dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached segmented images.\n",
      "Using cached denoised images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keypoints and descriptors: 100%|████████████████████████████████████████████| 37/37 [00:27<00:00,  1.37it/s]\n",
      "Extracting keypoints and descriptors: 100%|██████████████████████████████████████████| 287/287 [04:25<00:00,  1.08it/s]\n",
      "Matching descriptors: 100%|████████████████████████████████████████████████████████████| 37/37 [03:56<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing unknown painting threshold optimization for parameters HarrisLaplacian-ORB BruteForce [6, True]\n",
      "Best Threshold: 0.834499999999995\n",
      "Best F1 Score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "query_dir = \"./data/qsd1_w4/\"\n",
    "bbdd_dir = \"./data/BBDD/\"\n",
    "\n",
    "execute_unknown_painting_threshold_optimization(query_dir, bbdd_dir,\n",
    "                                                method=\"HarrisLaplacian-ORB\",\n",
    "                                                matching_method=\"BruteForce\",\n",
    "                                                matching_params=[cv2.NORM_HAMMING, True],\n",
    "                                                cache_segmented=True,\n",
    "                                                cache_denoised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca421f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
