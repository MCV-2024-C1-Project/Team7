{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2825e92e",
   "metadata": {},
   "source": [
    "# Comparison with last week & unknown system for DCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77946c94",
   "metadata": {},
   "source": [
    "In this notebook, a simple is developed and implemented to detect unknown paitings when using the DCT method from Week 3. Then, the method is executed (using unknown painting detection system) with the **QSD1_W4 dataset** so we can compare the results with this week's best method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc42d1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b898a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import shutil\n",
    "import tqdm as tqdm\n",
    "from skimage.measure import shannon_entropy\n",
    "from skimage.restoration import denoise_wavelet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.utils.distance_matrix import generate_results, create_distance_matrix_vectors\n",
    "from src.utils.images import load_and_preprocess_images, transform_images_color_space, load_images_from_directory\n",
    "from src.utils.DCT import compute_images_block_dct, extract_dct_coefficients_zigzag\n",
    "from src.utils.score_painting_retrieval import compute_mapk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc385e2",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7315f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dir = \"./data/qsd1_w4/\"\n",
    "bbdd_dir = \"./data/BBDD/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9750f",
   "metadata": {},
   "source": [
    "### Helper functions (from Week 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edges(image, threshold1=100, threshold2=200):\n",
    "    \"\"\"\n",
    "    Computes edges in an image using the Canny edge detection algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        image (ndarray): Input image, can be grayscale or RGB.\n",
    "        threshold1 (int): First threshold for the hysteresis procedure.\n",
    "        threshold2 (int): Second threshold for the hysteresis procedure.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Binary image with edges detected.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, threshold1, threshold2, apertureSize=3)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def closing(edges):\n",
    "    \"\"\"\n",
    "    Applies morphological transformations to close gaps in the edges.\n",
    "\n",
    "    Parameters:\n",
    "        edges (ndarray): Binary image with edges detected.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Binary image after morphological transformations.\n",
    "    \"\"\"\n",
    "    # Perform morphological closing to fill gaps in the edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (27, 27))\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "    return eroded\n",
    "\n",
    "def fill_with_convex_hull(edges):\n",
    "    \"\"\"\n",
    "    Fills the detected edges with convex hulls of the largest contours.\n",
    "\n",
    "    Parameters:\n",
    "        edges (ndarray): Binary image with edges detected.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - mask (ndarray): Binary mask with filled convex hulls.\n",
    "            - contours (list): List of contours found in the edges.\n",
    "    \"\"\"\n",
    "    # Find contours of the closed image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Take the two largest contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:2]\n",
    "\n",
    "    # Create an empty mask to draw filled convex hulls\n",
    "    mask = np.zeros_like(edges)\n",
    "\n",
    "    # Fill the convex hulls of the contours\n",
    "    for contour in contours:\n",
    "        if contour.size > 0:  # Ensure the contour is valid\n",
    "            convex_hull = cv2.convexHull(contour)\n",
    "            cv2.drawContours(mask, [convex_hull], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    return mask, contours\n",
    "\n",
    "def erosion(mask):\n",
    "    \"\"\"\n",
    "    Applies morphological transformations to erode the mask.\n",
    "\n",
    "    Parameters:\n",
    "        mask (ndarray): Binary mask with filled convex hulls.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Binary mask after morphological transformations.\n",
    "    \"\"\"\n",
    "    # Perform morphological erosion to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    eroded = cv2.erode(mask, kernel, iterations=1)\n",
    "\n",
    "    return eroded\n",
    "\n",
    "def remove_small_segments(mask, min_area=1000):\n",
    "    \"\"\"\n",
    "    Removes small segmented areas from a binary mask based on a minimum area threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        mask (ndarray): Binary mask where segmented areas are white (255) and background is black (0).\n",
    "        min_area (int): Minimum area (in pixels) to keep. Components smaller than this will be removed.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Cleaned binary mask with small components removed.\n",
    "    \"\"\"\n",
    "    # Label connected components in the mask\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "    # Create an empty mask to store the cleaned result\n",
    "    cleaned_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "\n",
    "    # Iterate through each component and keep only those with area above the threshold\n",
    "    for i in range(1, num_labels):  # Skip label 0 as it is the background\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= min_area:\n",
    "            # Retain the component in the cleaned mask\n",
    "            cleaned_mask[labels == i] = 255\n",
    "\n",
    "    return cleaned_mask\n",
    "\n",
    "def generate_masks(imgs_list):\n",
    "    \"\"\"\n",
    "    Generates masks for a list of images by detecting edges, closing gaps,\n",
    "    filling with convex hulls, and applying erosion.\n",
    "\n",
    "    Parameters:\n",
    "        imgs_list (list): List of images (ndarray) to process.\n",
    "\n",
    "    Returns:\n",
    "        list: List of binary masks (ndarray) for each image.\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    for img in imgs_list:\n",
    "        edges = compute_edges(img)\n",
    "        closed = closing(edges)\n",
    "        mask, contours = fill_with_convex_hull(closed)\n",
    "        mask = erosion(mask)\n",
    "        mask = remove_small_segments(mask)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "def high_pass_filter(image, ksize=5):\n",
    "    \"\"\"\n",
    "    Apply a high-pass filter to an image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image to be filtered.\n",
    "        ksize (int, optional): The size of the kernel to be used for the \n",
    "                               Gaussian blur. Must be an odd number. \n",
    "                               Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The high-pass filtered image.\n",
    "    \"\"\"\n",
    "    # Apply a Gaussian blur to get low-frequency components\n",
    "    low_pass = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "    # Subtract low-frequency components from the original image\n",
    "    high_pass = cv2.subtract(image, low_pass)\n",
    "    return high_pass\n",
    "\n",
    "def create_gaussian_pyramid(image, levels):\n",
    "    \"\"\"\n",
    "    Generates a Gaussian pyramid for a given image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image for which the pyramid is to be created.\n",
    "        levels (int): The number of levels in the pyramid.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of images representing the Gaussian pyramid, where the first element is the original image\n",
    "        and each subsequent element is a downsampled version of the previous one.\n",
    "    \"\"\"\n",
    "\n",
    "    pyramid = [image]\n",
    "    for i in range(levels):\n",
    "        image = cv2.pyrDown(image)\n",
    "        pyramid.append(image)\n",
    "    return pyramid\n",
    "\n",
    "def create_laplacian_pyramid(gaussian_pyramid):\n",
    "    \"\"\"\n",
    "    Generates a Laplacian pyramid from a given Gaussian pyramid.\n",
    "\n",
    "    Args:\n",
    "        gaussian_pyramid (list): A list of images representing the Gaussian pyramid, where the first element\n",
    "                                 is the original image and each subsequent element is a downsampled version\n",
    "                                 of the previous one.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of images representing the Laplacian pyramid, where each element is the difference\n",
    "              between the Gaussian-blurred image at that level and the expanded version of the next level.\n",
    "    \"\"\"\n",
    "    laplacian_pyramid = []\n",
    "    for i in range(len(gaussian_pyramid)-1, 0, -1):\n",
    "        size = (gaussian_pyramid[i-1].shape[1], gaussian_pyramid[i-1].shape[0])\n",
    "        expanded = cv2.pyrUp(gaussian_pyramid[i], dstsize=size)\n",
    "        laplacian = cv2.subtract(gaussian_pyramid[i-1], expanded)\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "    return laplacian_pyramid\n",
    "\n",
    "def apply_nlm_filter(laplacian_pyramid, h):\n",
    "    \"\"\"\n",
    "    Apply Non-Local Means (NLM) denoising filter to each level of a Laplacian pyramid.\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list of numpy.ndarray): A list of 2D arrays representing the Laplacian pyramid levels.\n",
    "        h (float): Parameter regulating filter strength. Higher h value removes noise better but also removes details.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: A list of 2D arrays representing the denoised Laplacian pyramid levels.\n",
    "    \"\"\"\n",
    "    # Apply NLM denoising to each level of the Laplacian pyramid\n",
    "    denoised_pyramid = []\n",
    "    for lap in laplacian_pyramid:\n",
    "        denoised_pyramid.append(cv2.fastNlMeansDenoising(lap, None, h, 7, 21))  # You can adjust the NLM parameters if needed\n",
    "    return denoised_pyramid\n",
    "\n",
    "def apply_bilateral_filter(laplacian_pyramid, d, sigma_color, sigma_space):\n",
    "    \"\"\"\n",
    "    Apply a bilateral filter to each level of a Laplacian pyramid.\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list of numpy.ndarray): A list of 2D arrays representing the Laplacian pyramid levels.\n",
    "        d (int): Diameter of each pixel neighborhood used during filtering.\n",
    "        sigma_color (float): Filter sigma in the color space. A larger value means that\n",
    "                             farther colors within the pixel neighborhood will be mixed together.\n",
    "        sigma_space (float): Filter sigma in the coordinate space. A larger value means that\n",
    "                             farther pixels will influence each other as long as their colors are close enough.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: A list of 2D arrays representing the denoised Laplacian pyramid levels.\n",
    "    \"\"\"\n",
    "    denoised_pyramid = []\n",
    "    for i, lap in enumerate(laplacian_pyramid):\n",
    "        if i < len(laplacian_pyramid):\n",
    "            denoised_pyramid.append(cv2.bilateralFilter(lap, d, sigma_color, sigma_space))\n",
    "        else:\n",
    "            denoised_pyramid.append(lap)\n",
    "    return denoised_pyramid\n",
    "\n",
    "def apply_median_filter(laplacian_pyramid, ksize):\n",
    "    \"\"\"\n",
    "    Apply a median filter to each level of a Laplacian pyramid.\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list of numpy.ndarray): A list of 2D arrays representing the Laplacian pyramid levels.\n",
    "        ksize (int): Size of the kernel to be used for the median filter. Must be an odd number.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: A list of 2D arrays representing the denoised Laplacian pyramid levels.\n",
    "    \"\"\"\n",
    "    denoised_pyramid = []\n",
    "    for i, lap in enumerate(laplacian_pyramid):\n",
    "        if i < len(laplacian_pyramid):\n",
    "            denoised_pyramid.append(cv2.medianBlur(lap, ksize))\n",
    "        else:\n",
    "            denoised_pyramid.append(lap)\n",
    "    return denoised_pyramid\n",
    "\n",
    "def apply_gaussian_filter(laplacian_pyramid, ksize):\n",
    "    \"\"\"\n",
    "    Apply a Gaussian filter to each level of a Laplacian pyramid.\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list of numpy.ndarray): A list of 2D arrays representing the Laplacian pyramid levels.\n",
    "        ksize (int): Size of the kernel to be used for the Gaussian filter. Must be an odd number.\n",
    "\n",
    "    Returns:\n",
    "        list of numpy.ndarray: A list of 2D arrays representing the denoised Laplacian pyramid levels.\n",
    "    \"\"\"\n",
    "    denoised_pyramid = []\n",
    "    for i, lap in enumerate(laplacian_pyramid):\n",
    "        if i < len(laplacian_pyramid):\n",
    "            denoised_pyramid.append(cv2.GaussianBlur(lap, (ksize, ksize), 0))\n",
    "        else:\n",
    "            denoised_pyramid.append(lap)\n",
    "    return denoised_pyramid\n",
    "\n",
    "def reconstruct_image(laplacian_pyramid, gaussian_base):\n",
    "    \"\"\"\n",
    "    Reconstructs an image from its Laplacian pyramid and a Gaussian base image.\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list of numpy.ndarray): A list of images representing the Laplacian pyramid.\n",
    "        gaussian_base (numpy.ndarray): The base image at the lowest resolution of the Gaussian pyramid.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The reconstructed image.\n",
    "    \"\"\"\n",
    "    current_image = gaussian_base\n",
    "    for laplacian in laplacian_pyramid:\n",
    "        size = (laplacian.shape[1], laplacian.shape[0])\n",
    "        current_image = cv2.pyrUp(current_image, dstsize=size)\n",
    "        current_image = cv2.add(current_image, laplacian)\n",
    "    return current_image\n",
    "\n",
    "def enhance_image_with_hp(denoised_image, ksize=5):\n",
    "    \"\"\"\n",
    "    Enhance a denoised image by adding high-frequency details using a high-pass filter.\n",
    "\n",
    "    Args:\n",
    "        denoised_image (numpy.ndarray): The input denoised image.\n",
    "        ksize (int, optional): The kernel size for the high-pass filter. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The enhanced image with high-frequency details added.\n",
    "    \"\"\"\n",
    "    high_pass_details = high_pass_filter(denoised_image, ksize)\n",
    "    # Add high-frequency details back to the denoised image\n",
    "    enhanced_image = cv2.add(denoised_image, high_pass_details)\n",
    "    return enhanced_image\n",
    "\n",
    "def laplacian_pyramid_denoising(image, lowpass_params, pyramid_levels, method):\n",
    "    \"\"\"\n",
    "    Perform denoising on an image using Laplacian pyramid decomposition and specified lowpass filtering method.\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): The input image to be denoised.\n",
    "        lowpass_params (dict): Parameters for the lowpass filter method.\n",
    "        pyramid_levels (int): The number of levels in the pyramid.\n",
    "        method (str): The lowpass filter method to be applied.\n",
    "                      Supported methods are 'gaussian', 'median', 'bilateral', and 'nlm'.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The denoised image reconstructed from the Laplacian pyramid.\n",
    "    \"\"\"\n",
    "    gaussian_pyramid = create_gaussian_pyramid(image, pyramid_levels)\n",
    "    laplacian_pyramid = create_laplacian_pyramid(gaussian_pyramid)\n",
    "\n",
    "    # Apply specified lowpass filter on the Laplacian pyramid\n",
    "    if method == 'gaussian':\n",
    "        denoised_pyramid = apply_gaussian_filter(laplacian_pyramid, **lowpass_params)\n",
    "    elif method == 'median':\n",
    "        denoised_pyramid = apply_median_filter(laplacian_pyramid, **lowpass_params)\n",
    "    elif method == 'bilateral':\n",
    "        denoised_pyramid = apply_bilateral_filter(laplacian_pyramid, **lowpass_params)\n",
    "    elif method == 'nlm':\n",
    "        denoised_pyramid = apply_nlm_filter(laplacian_pyramid, **lowpass_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported lowpass filter in Laplacian Pyramid: {method}\")\n",
    "\n",
    "    return reconstruct_image(denoised_pyramid, gaussian_pyramid[-1])\n",
    "\n",
    "def wavelet_denoising_skimage(image, wavelet='db1', mode='soft', rescale_sigma=True):\n",
    "    \"\"\"\n",
    "    Apply wavelet denoising using skimage's denoise_wavelet function.\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): Input noisy color image.\n",
    "        wavelet (str): Type of wavelet to use (e.g., 'db1' for Daubechies).\n",
    "        mode (str): Thresholding mode ('soft' or 'hard').\n",
    "        rescale_sigma (bool): Whether to rescale the noise's standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Denoised image.\n",
    "    \"\"\"\n",
    "    # Perform wavelet denoising\n",
    "    denoised_image = denoise_wavelet(image, wavelet=wavelet, mode=mode, rescale_sigma=rescale_sigma)\n",
    "    \n",
    "    # Convert to uint8 format for visualization\n",
    "    denoised_image = (denoised_image * 255).astype(np.uint8)\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "def apply_dct_denoising(image, threshold=30):\n",
    "    \"\"\"\n",
    "    Apply DCT-based denoising to an image.\n",
    "    \n",
    "    This function performs denoising using the Discrete Cosine Transform (DCT). \n",
    "    It applies DCT to each color channel of the image, thresholds the DCT coefficients \n",
    "    to zero out small values (which are assumed to be noise), and then applies the \n",
    "    inverse DCT to reconstruct the denoised image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image to be denoised.\n",
    "        threshold (float): The threshold value for zeroing out small DCT coefficients. \n",
    "                           Coefficients with absolute values below this threshold will be set to zero.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The denoised image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert image to float32 for better precision in the DCT process\n",
    "    image = np.float32(image) / 255.0\n",
    "    \n",
    "    # Apply DCT to each color channel separately\n",
    "    dct_channels = []\n",
    "    for i in range(3):  # Assuming RGB\n",
    "        # Apply 2D DCT (Discrete Cosine Transform)\n",
    "        dct = cv2.dct(image[:, :, i])\n",
    "        \n",
    "        # Zero out small coefficients (thresholding)\n",
    "        dct[np.abs(dct) < threshold] = 0\n",
    "        \n",
    "        # Apply inverse DCT to reconstruct the denoised channel\n",
    "        idct = cv2.idct(dct)\n",
    "        dct_channels.append(idct)\n",
    "    \n",
    "    # Merge the three channels back into an image\n",
    "    denoised_image = cv2.merge(dct_channels)\n",
    "    \n",
    "    # Clip values to [0, 1] range and convert back to uint8\n",
    "    denoised_image = np.clip(denoised_image * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "def variance_noise_estimation(image, color_space):\n",
    "    if color_space == 'grayscale':\n",
    "        channel = image\n",
    "    elif color_space in ['lab', 'yuv']:\n",
    "        channel = image[:, :, 0]  # Use luminance channel\n",
    "    else:\n",
    "        channel = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return np.var(channel)\n",
    "\n",
    "def entropy_noise_estimation(image, color_space):\n",
    "    if color_space == 'grayscale':\n",
    "        channel = image\n",
    "    elif color_space in ['lab', 'yuv']:\n",
    "        channel = image[:, :, 0]  # Use luminance channel\n",
    "    else:\n",
    "        channel = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return shannon_entropy(channel)\n",
    "\n",
    "def laplacian_noise_estimation(image, color_space):\n",
    "    if color_space == 'grayscale':\n",
    "        channel = image\n",
    "    elif color_space in ['lab', 'yuv']:\n",
    "        channel = image[:, :, 0]\n",
    "    else:\n",
    "        channel = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    laplacian = cv2.Laplacian(channel, cv2.CV_64F)\n",
    "    return np.mean(np.abs(laplacian))\n",
    "\n",
    "def wavelet_noise_estimation(image, color_space):\n",
    "    if color_space == 'grayscale':\n",
    "        channel = image\n",
    "    elif color_space in ['lab', 'yuv']:\n",
    "        channel = image[:, :, 0]  # Use luminance channel\n",
    "    else:\n",
    "        channel = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    coeffs = pywt.wavedec2(channel, 'haar', level=2)\n",
    "    high_freq_coeffs = coeffs[-1]\n",
    "    return np.std(np.hstack(high_freq_coeffs))\n",
    "\n",
    "def apply_denoising(image, method, lowpass_params=None, highpass=False, wavelet_params=None, dct_params=None, pyramid_levels=None):\n",
    "    # Select denoising method\n",
    "    if pyramid_levels:\n",
    "        denoised_image = laplacian_pyramid_denoising(image, lowpass_params, pyramid_levels, method)\n",
    "\n",
    "    elif method == 'wavelet' and wavelet_params:\n",
    "        denoised_image = wavelet_denoising_skimage(image, **wavelet_params)\n",
    "\n",
    "    elif method == 'dct' and dct_params:\n",
    "        denoised_image = apply_dct_denoising(image, **dct_params)\n",
    "    \n",
    "    elif method == 'gaussian':\n",
    "        denoised_image = cv2.GaussianBlur(image, (lowpass_params['ksize'], lowpass_params['ksize']), 0)\n",
    "\n",
    "    elif method == 'median':\n",
    "        denoised_image = cv2.medianBlur(image, lowpass_params['ksize'])\n",
    "\n",
    "    elif method == 'bilateral':\n",
    "        d, sigma_color, sigma_space = lowpass_params['d'], lowpass_params['sigma_color'], lowpass_params['sigma_space']\n",
    "        denoised_image = cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
    "    \n",
    "    elif method == 'nlm':\n",
    "        h_luminance, h_color = lowpass_params['h_luminance'], lowpass_params['h_color']\n",
    "        denoised_image = cv2.fastNlMeansDenoising(image, None, h_luminance, h_color, 7, 21)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported denoising method: {method}\")\n",
    "\n",
    "    # Apply additional high-pass filtering if requested\n",
    "    if highpass:\n",
    "        denoised_image = enhance_image_with_hp(denoised_image, ksize=5)\n",
    "\n",
    "    return denoised_image\n",
    "\n",
    "def create_denoised_dataset(noisy_dataset_path, denoised_dataset_path, method, lowpass_params=None, highpass=False, wavelet_params=None, dct_params=None, pyramid_levels=None, noise_method=None, noise_threshold=0):\n",
    "    \"\"\"\n",
    "    Create a denoised dataset from a noisy dataset.\n",
    "\n",
    "    Args:\n",
    "    - noisy_dataset_path: Path to the directory containing noisy images.\n",
    "    - denoised_dataset_path: Path to save denoised images.\n",
    "    - method: The denoising method ('gaussian', 'median', 'bilateral', 'nlm', 'wavelet', 'dct', 'laplacian', 'lowpass_highpass').\n",
    "    - lowpass_params: Parameters for low-pass filtering.\n",
    "    - highpass: Boolean to indicate if a high-pass filter should be applied after denoising.\n",
    "    - wavelet_params: Parameters for wavelet denoising.\n",
    "    - dct_params: Parameters for DCT denoising.\n",
    "    - pyramid_levels: Number of levels for Laplacian pyramid processing.\n",
    "    - noise_method: Method for estimating noise ('variance', 'entropy', 'laplacian', 'wavelet').\n",
    "    - noise_threshold: Threshold for noise estimation to decide whether to denoise the image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the denoised dataset directory if it doesn't exist\n",
    "    os.makedirs(denoised_dataset_path, exist_ok=True)\n",
    "\n",
    "    # Iterate over all images in the noisy dataset directory\n",
    "    for filename in tqdm.tqdm(os.listdir(noisy_dataset_path), desc=\"Denoising images\"):\n",
    "        if filename.lower().endswith('.jpg'):  # Check for valid image file extensions\n",
    "            # Construct the full path to the noisy image\n",
    "            noisy_image_path = os.path.join(noisy_dataset_path, filename)\n",
    "\n",
    "            # Read the noisy image\n",
    "            noisy_image = cv2.imread(noisy_image_path)\n",
    "\n",
    "            if not noise_method:\n",
    "                denoised_image = apply_denoising(\n",
    "                        noisy_image,\n",
    "                        method,\n",
    "                        lowpass_params=lowpass_params,\n",
    "                        highpass=highpass,\n",
    "                        wavelet_params=wavelet_params,\n",
    "                        dct_params=dct_params,\n",
    "                        pyramid_levels=pyramid_levels\n",
    "                    )\n",
    "                \n",
    "                denoised_image_path = os.path.join(denoised_dataset_path, filename)\n",
    "                cv2.imwrite(denoised_image_path, denoised_image)\n",
    "\n",
    "            else:\n",
    "                # Estimate the noise level using the specified method\n",
    "                if noise_method == 'variance':\n",
    "                    noise_estimate = variance_noise_estimation(noisy_image, 'grayscale')\n",
    "                elif noise_method == 'entropy':\n",
    "                    noise_estimate = entropy_noise_estimation(noisy_image, 'grayscale')\n",
    "                elif noise_method == 'laplacian':\n",
    "                    noise_estimate = laplacian_noise_estimation(noisy_image, 'grayscale')\n",
    "                elif noise_method == 'wavelet':\n",
    "                    noise_estimate = wavelet_noise_estimation(noisy_image, 'grayscale')\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported noise estimation method: {noise_method}\")\n",
    "\n",
    "                # Print the noise estimate for debugging\n",
    "                #print(f\"Noise estimate for {filename}: {noise_estimate}\")\n",
    "\n",
    "                # Decide whether to denoise based on the estimated noise\n",
    "                if noise_estimate > noise_threshold:\n",
    "                    # Apply the denoising method\n",
    "                    denoised_image = apply_denoising(\n",
    "                        noisy_image,\n",
    "                        method,\n",
    "                        lowpass_params=lowpass_params,\n",
    "                        highpass=highpass,\n",
    "                        wavelet_params=wavelet_params,\n",
    "                        dct_params=dct_params,\n",
    "                        pyramid_levels=pyramid_levels\n",
    "                    )\n",
    "\n",
    "                    # Save the denoised image\n",
    "                    denoised_image_path = os.path.join(denoised_dataset_path, filename)\n",
    "                    cv2.imwrite(denoised_image_path, denoised_image)\n",
    "                    #print(f\"Denoised image saved to: {denoised_image_path}\")\n",
    "                else:\n",
    "                    print(f\"Skipping denoising for {filename} due to low noise estimate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06251fba",
   "metadata": {},
   "source": [
    "### Main function to generate results (from Week 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTION\n",
    "# ===========================================================\n",
    "def generate_submission_qst2(query_dir, bbdd_dir):\n",
    "\n",
    "    # REMOVE NOISE FROM QUERY IMAGES FOR SEGMENTATION\n",
    "    # ========================================================\n",
    "\n",
    "    # Create a new directory for denoised images\n",
    "    denoised_for_segmentation_queries_dir = 'data/denoised_for_segmentation_queries_dir'\n",
    "\n",
    "    # Remove previous denoised images\n",
    "    if os.path.exists(denoised_for_segmentation_queries_dir):\n",
    "        shutil.rmtree(denoised_for_segmentation_queries_dir)\n",
    "\n",
    "    create_denoised_dataset(\n",
    "        noisy_dataset_path = query_dir,\n",
    "        denoised_dataset_path = denoised_for_segmentation_queries_dir,\n",
    "        method='gaussian',\n",
    "        lowpass_params={'ksize': 3},\n",
    "        highpass=False\n",
    "    )\n",
    "    \n",
    "    # Read denoised images\n",
    "    rgb_queries_denoised = []\n",
    "    for filename in os.listdir(denoised_for_segmentation_queries_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(denoised_for_segmentation_queries_dir, filename)\n",
    "            img_rgb = cv2.imread(img_path)\n",
    "            if img_rgb is not None:\n",
    "                rgb_queries_denoised.append(img_rgb)\n",
    "            else:\n",
    "                print(f\"Warning: Failed to read {img_path}\")\n",
    "\n",
    "    # DETECT PAINTINGS IN QUERIES (SEGMENTATION)\n",
    "    # ========================================================\n",
    "\n",
    "    masks_queries_dir = \"data/masks_queries_dir\"\n",
    "    cropped_queries_dir = \"data/cropped_queries_dir\"\n",
    "\n",
    "    # Remove previous masks and cropped images\n",
    "    if os.path.exists(masks_queries_dir):\n",
    "        shutil.rmtree(masks_queries_dir)\n",
    "    if os.path.exists(cropped_queries_dir):\n",
    "        shutil.rmtree(cropped_queries_dir)\n",
    "\n",
    "    # Create new directories for masks and cropped images\n",
    "    os.makedirs(masks_queries_dir, exist_ok=True)\n",
    "    os.makedirs(cropped_queries_dir, exist_ok=True)\n",
    "\n",
    "    masks = generate_masks(rgb_queries_denoised)\n",
    "\n",
    "    # Read query images\n",
    "    rgb_queries = []\n",
    "    for filename in os.listdir(query_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(query_dir, filename)\n",
    "            img_rgb = cv2.imread(img_path)\n",
    "            if img_rgb is not None:\n",
    "                rgb_queries.append(img_rgb)\n",
    "            else:\n",
    "                print(f\"Warning: Failed to read {img_path}\")\n",
    "    \n",
    "    paintings_per_image = []\n",
    "    image_counter = 0\n",
    "\n",
    "    for i, mask in enumerate(tqdm.tqdm(masks, desc=\"Generating segmentation masks and cropping images\")):\n",
    "        # Save the mask\n",
    "        mask_filename = f\"{i:05d}.png\"\n",
    "        masks_save_path = os.path.join(masks_queries_dir, mask_filename)\n",
    "        cv2.imwrite(masks_save_path, mask)\n",
    "\n",
    "        # Detect connected components in the mask\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "        # Count paintings (objects of interest) in the current image\n",
    "        painting_count = 0\n",
    "\n",
    "        # Collect all valid components (ignoring background label 0)\n",
    "        components = []\n",
    "\n",
    "        for j in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[j]\n",
    "\n",
    "            components.append((x, y, w, h, area))  # Store component details\n",
    "\n",
    "        # Sort components from leftmost to rightmost (higher x to lower x)\n",
    "        components_sorted = sorted(components, key=lambda c: c[0])\n",
    "\n",
    "        # Iterate over sorted components and save them\n",
    "        for (x, y, w, h, area) in components_sorted:\n",
    "            # Extract and save the cropped region\n",
    "            cropped_result = rgb_queries[i][y:y+h, x:x+w]\n",
    "            cropped_filename = f\"{image_counter:05d}.jpg\"\n",
    "            cropped_save_path = os.path.join(cropped_queries_dir, cropped_filename)\n",
    "            cv2.imwrite(cropped_save_path, cropped_result)\n",
    "\n",
    "            # Increment the counter for unique naming\n",
    "            image_counter += 1\n",
    "            painting_count += 1\n",
    "\n",
    "        # Add the number of paintings detected for this image to the list\n",
    "        paintings_per_image.append(painting_count)\n",
    "\n",
    "    # Save the list of frame counts per image in a single .pkl file\n",
    "    with open(\"data/paintings_per_image.pkl\", \"wb\") as f:\n",
    "        pickle.dump(paintings_per_image, f)\n",
    "\n",
    "    # All images are saved in the same temporary directory, in order (/cropped_queries_dir)\n",
    "    # A list is saved indicating the number of paintings per image (paintings_per_image.pkl)\n",
    "\n",
    "    # REMOVE NOISE FROM QUERY IMAGES\n",
    "    # =========================================================\n",
    "    \n",
    "    # Load list containing paintings per image\n",
    "    with open('data/paintings_per_image.pkl', 'rb') as file:\n",
    "        paintings_per_image = pickle.load(file)\n",
    "\n",
    "    denoised_paintings_folder = 'data/denoised_paintings'\n",
    "\n",
    "    # Remove previous paintings\n",
    "    if os.path.exists(denoised_paintings_folder):\n",
    "        shutil.rmtree(denoised_paintings_folder)\n",
    "\n",
    "    # Create new temporary directory for denoised images\n",
    "    os.makedirs(denoised_paintings_folder, exist_ok=True)\n",
    "    \n",
    "    # Using denoising method 5\n",
    "    create_denoised_dataset(\n",
    "        noisy_dataset_path = cropped_queries_dir,\n",
    "        denoised_dataset_path = denoised_paintings_folder,\n",
    "        method='wavelet',\n",
    "        wavelet_params={'wavelet':'db1', 'mode':'soft', 'rescale_sigma':True},\n",
    "        highpass=False\n",
    "    )\n",
    "    \n",
    "    # EXTRACT TEXTURE FEATURES FROM DENOISED QUERIES AND BBDD\n",
    "    # =========================================================\n",
    "    \n",
    "    # Using DCT with best parameters\n",
    "    color = \"V\"\n",
    "    distance_measure = \"Cosine\"\n",
    "    block_size = 64\n",
    "    num_coefs = 64\n",
    "\n",
    "    # Load denoised query paintings and bbdd images\n",
    "    query_images = load_and_preprocess_images(denoised_paintings_folder, extension=\".jpg\")\n",
    "    bbdd_images = load_and_preprocess_images(bbdd_dir, extension=\".jpg\")\n",
    "\n",
    "    # Transform color space of the images\n",
    "    query_images_color = transform_images_color_space(query_images, color_space=color)\n",
    "    bbdd_images_color = transform_images_color_space(bbdd_images, color_space=color)\n",
    "\n",
    "    # Compute the DCT of the images\n",
    "    query_dct_blocks = compute_images_block_dct(query_images_color, block_size)\n",
    "    bbdd_dct_blocks = compute_images_block_dct(bbdd_images_color, block_size)\n",
    "\n",
    "    # Extract first K coefficients of images DCTs\n",
    "    query_feature_vectors = extract_dct_coefficients_zigzag(query_dct_blocks, num_coefs, block_size)\n",
    "    bbdd_feature_vectors = extract_dct_coefficients_zigzag(bbdd_dct_blocks, num_coefs, block_size)\n",
    "    \n",
    "    \n",
    "    # CALCULATE DISTANCES AND ORDER RESULTS\n",
    "    # =========================================================\n",
    "    \n",
    "    # Calculate distance matrix\n",
    "    distance_matrix = create_distance_matrix_vectors(query_feature_vectors, \n",
    "                                                     bbdd_feature_vectors,\n",
    "                                                     distance_measure)\n",
    "    # Generate sorted results\n",
    "    results = generate_results(distance_matrix, distance_measure)\n",
    "    \n",
    "    # GENERATE SUBMISSION\n",
    "    # =========================================================\n",
    "    \n",
    "    # Top K best results\n",
    "    k=10\n",
    "    \n",
    "    # Extracting the top K best results from each prediction\n",
    "    results_topK = np.array(results)[:,:k].tolist()\n",
    "    \n",
    "    # Final sumbission list of lists of lists\n",
    "    submission = []\n",
    "    \n",
    "    # Add the top K predictions depending on the number of paintings per image\n",
    "    i = 0\n",
    "    for num_paintings in tqdm.tqdm(paintings_per_image, desc=\"Saving top K predictions\"):\n",
    "        if num_paintings == 1:\n",
    "            submission.append([results_topK[i]])\n",
    "            i += 1\n",
    "        elif num_paintings == 2:\n",
    "            submission.append([results_topK[i], results_topK[i+1]])\n",
    "            i += 2\n",
    "        \n",
    "    return distance_matrix, submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840e38e",
   "metadata": {},
   "source": [
    "### Additional helper functions for this study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841320b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_painting_entries(list1, list2):\n",
    "    \n",
    "    # Check if both lists are of the same size\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same size.\")\n",
    "    \n",
    "    # Iterate over list2 with index to find where elements are sublists of length 2\n",
    "    indices_to_remove = [i for i, item in enumerate(list2) if isinstance(item, list) and len(item) == 2]\n",
    "    \n",
    "    # Remove elements in reverse order to avoid index shifting\n",
    "    for index in sorted(indices_to_remove, reverse=True):\n",
    "        del list1[index]\n",
    "        del list2[index]\n",
    "    \n",
    "    return list1, list2\n",
    "\n",
    "def order_results_by_num_paintings(results, paintings_per_image):\n",
    "    \n",
    "    ordered_results = []\n",
    "    i = 0\n",
    "    for num_paintings in paintings_per_image:\n",
    "        if num_paintings == 1:\n",
    "            ordered_results.append([results[i]])\n",
    "            i += 1\n",
    "        elif num_paintings == 2:\n",
    "            ordered_results.append([results[i], results[i+1]])\n",
    "            i += 2\n",
    "            \n",
    "    return ordered_results\n",
    "\n",
    "def generate_submission(results, paintings_per_image):\n",
    "    \"\"\"\n",
    "    Gets the top 1 bbdd image for each query, taking into account\n",
    "    whether there were one or two paintings in the image.\n",
    "    \n",
    "    Args:\n",
    "    - results: list of lists with the ordered top results for each query\n",
    "    - paintings_per_image: list with number of paintings in every query image\n",
    "    \n",
    "    Returns:\n",
    "    - submission: a list of lists in the sumbission format\n",
    "    \"\"\"\n",
    "    \n",
    "    submission = []\n",
    "    i = 0\n",
    "    for num_paintings in paintings_per_image:\n",
    "        if num_paintings == 1:\n",
    "            submission.append([results[i][0]])\n",
    "            i += 1\n",
    "        elif num_paintings == 2:\n",
    "            submission.append([results[i][0], results[i+1][0]])\n",
    "            i += 2\n",
    "            \n",
    "    return submission\n",
    "\n",
    "def analyze_and_plot_groups(list1, list2):\n",
    "    # Separate values in list1 based on conditions in list2\n",
    "    group1 = [val for val, flag in zip(list1, list2) if flag == -1]\n",
    "    group2 = [val for val, flag in zip(list1, list2) if flag != -1]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean1, std1 = np.mean(group1), np.std(group1)\n",
    "    mean2, std2 = np.mean(group2), np.std(group2)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Group 1 (flag -1): Mean =\", mean1, \", Standard Deviation =\", std1)\n",
    "    print(\"Group 2 (flag not -1): Mean =\", mean2, \", Standard Deviation =\", std2)\n",
    "    \n",
    "    # Define bins from 0.25 to 0.60 with steps of 0.05\n",
    "    bins = np.arange(0.25, 0.65, 0.05)\n",
    "    \n",
    "    # Plot setup with specified height ratios for each subplot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 7), gridspec_kw={'height_ratios': [3, 1.5]})\n",
    "    \n",
    "    # Histogram plot\n",
    "    ax1.hist(group1, bins=bins, alpha=0.5, color='blue', label='Unknown paintings')\n",
    "    ax1.hist(group2, bins=bins, alpha=0.5, color='orange', label='Known paintings')\n",
    "    ax1.tick_params(axis='both', labelsize=13)\n",
    "    ax1.set_ylabel('Frequency', fontsize=15)\n",
    "    ax1.set_title('Top 1 similarity values distribution using DCT', fontsize=16)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Horizontal line plot of data points\n",
    "    ax2.scatter(group1, np.zeros_like(group1), color='blue', label='Unknown paintings', s=50)\n",
    "    ax2.scatter(group2, np.zeros_like(group2), color='orange', label='Known paintings', s=50)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel('Similarity', fontsize=15)\n",
    "    ax2.set_xlim(0.232, 0.618)\n",
    "    ax2.tick_params(axis='x', labelsize=13)\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Unknown_study_DCT.jpg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91ca53",
   "metadata": {},
   "source": [
    "### Load groundtruth and paintings per image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/qsd1_w4/gt_corresps.pkl', 'rb') as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "\n",
    "# This is used to group the paintings depending on whether 1 or 2 paintings have\n",
    "# been detected for a certain image\n",
    "with open(\"data/paintings_per_image.pkl\", \"rb\") as f:\n",
    "    paintings_per_image = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432a6c0",
   "metadata": {},
   "source": [
    "### Unknown painting study and detection system creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bce1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_matrix, pre_submission = generate_submission_qst2(query_dir, bbdd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8561de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 1 distance for each query image\n",
    "dm_top1_distance = [max(sublist) for sublist in distance_matrix]\n",
    "\n",
    "# Group paintings depending on number of paintings detected\n",
    "ordered_matchings = order_results_by_num_paintings(dm_top1_distance, paintings_per_image)\n",
    "\n",
    "# Remove multiple paintings so that bad cropping issues are not taken into account\n",
    "filtered_matchings, filtered_gt = remove_multiple_painting_entries(ordered_matchings, ground_truth)\n",
    "\n",
    "# Preprocess distances and groundtruth\n",
    "flat_distnaces = [distance[0] for distance in filtered_matchings]\n",
    "flat_gt = [value[0] for value in ground_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different distributions\n",
    "analyze_and_plot_groups(flat_distnaces, flat_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign threshold by visual inspection\n",
    "threshold = 0.35\n",
    "\n",
    "# Convert distances and groundtruth to binary vectors (1 unknown, 0 known)\n",
    "pred_vector = [1 if value < threshold else 0 for value in flat_distnaces]\n",
    "gt_vector = [1 if value == -1 else 0 for value in flat_gt]\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score(gt_vector, pred_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dc8af",
   "metadata": {},
   "source": [
    "### Unknown painting mask creation and DCT evaluation with QSD1_W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b53ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask of unknown paintings to generate the final submission\n",
    "unknown_mask = [1 if value < threshold else 0 for value in dm_top1_distance]\n",
    "\n",
    "# Process the submission generated by the DCT main function to\n",
    "# apply the mask of unknown paintings\n",
    "flattened_submission = [item for sublist in pre_submission for item in sublist]\n",
    "\n",
    "masked_submission = []\n",
    "for mask, pred in zip(unknown_mask, flattened_submission):\n",
    "    if mask==1:\n",
    "        masked_submission.append([-1])\n",
    "    else:\n",
    "        masked_submission.append(pred)\n",
    "\n",
    "# Generate the final submission be grouping again the paintings depending\n",
    "# on the number of paintings generated\n",
    "submission = generate_submission(masked_submission, paintings_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final MAP@1 value\n",
    "compute_mapk(ground_truth, submission, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ac818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
